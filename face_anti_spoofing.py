# -*- coding: utf-8 -*-
"""face_anti_spoofing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Y5R3Go-b-wttB8d_v7fpm_IpZ9r3Lqj2

# Face anti-spoofing

## Getting the helper functions
"""

# Get helper functions file
!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py

# Importing the helper functions
from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, compare_historys, walk_through_dir

"""# Importing Data"""

# Unzip the data
unzip_data("face_anti_spoofing_data.zip")

# Training and testing directories
train_dir = "face_anti_spoofing_data/"
# train_dir = "face_anti_spoofing_data/train/"
# test_dir = "face_anti_spoofing_data/test/"

# How many images/classes are there?
walk_through_dir("face_anti_spoofing_data")

"""# Data Preprocessing"""

# Setup data inputs
from tensorflow.keras.preprocessing.image import ImageDataGenerator

IMAGE_SHAPE = (224, 224)
BATCH_SIZE = 32

import tensorflow as tf

train_dir = "face_anti_spoofing_data/"
image_generator = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=0.2,rescale=1/255.,rotation_range=10,zoom_range=0.2)
train_datagen = image_generator.flow_from_directory(directory=train_dir,
                                                     subset='training',
                                                     target_size=IMAGE_SHAPE,
                                                     batch_size=BATCH_SIZE,
                                                     class_mode="binary",
                                                     shuffle = True)
test_datagen = image_generator.flow_from_directory(directory=train_dir,
                                                   subset='validation',
                                                   target_size=IMAGE_SHAPE,
                                                   batch_size=BATCH_SIZE,
                                                   class_mode="binary",
                                                   shuffle = True)


# train_datagen = ImageDataGenerator(rescale=1/255.,rotation_range=10,zoom_range=0.2)
# test_datagen = ImageDataGenerator(rescale=1/255.,rotation_range=10,zoom_range=0.2)


# print("Training images:")
# train_data = train_datagen.flow_from_directory(train_dir,
#                                                target_size=IMAGE_SHAPE,
#                                                batch_size=BATCH_SIZE,
#                                                class_mode="binary",
#                                                shuffle = True)

# print("Testing images:")
# test_data = train_datagen.flow_from_directory(test_dir,
#                                               target_size=IMAGE_SHAPE,
#                                               batch_size=BATCH_SIZE,
#                                               class_mode="binary",
#                                               shuffle = True)

"""# Transfer learning : Feature extraction (without fine tuning)"""

import tensorflow as tf
import tensorflow_hub as hub
from tensorflow.keras import layers

# Resnet 50 V2 feature vector
resnet_url = "https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5"

def create_model(model_url):
  """Takes a TensorFlow Hub URL and creates a Keras Sequential model with it.
  
  Args:
    model_url (str): A TensorFlow Hub feature extraction URL.

  Returns:
    An uncompiled Keras Sequential model with model_url as feature
    extractor layer
  """
  # Download the pretrained model and save it as a Keras layer
  feature_extractor_layer = hub.KerasLayer(model_url,
                                           trainable=False, # freeze the underlying patterns
                                           name='feature_extraction_layer',
                                           input_shape=IMAGE_SHAPE+(3,)) # define the input image shape
  
  # Create our own model
  model = tf.keras.Sequential([
    feature_extractor_layer, # use the feature extraction layer as the base
    layers.Dense(1, activation='sigmoid', name='output_layer') # create our own output layer      
  ])

  return model

# Create model
resnet_model = create_model(resnet_url)

# Compile
resnet_model.compile(loss='binary_crossentropy',
                     optimizer=tf.keras.optimizers.Adam(),
                     metrics=['accuracy'])

# Setup checkpoint path
checkpoint_path = "model_checkpoints_weights/checkpoint.ckpt" # note: remember saving directly to Colab is temporary

# Create a ModelCheckpoint callback that saves the model's weights only
checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,
                                                         save_weights_only=True, # set to False to save the entire model
                                                         save_best_only=False, # set to True to save only the best model instead of a model every epoch 
                                                         save_freq="epoch", # save every epoch
                                                         verbose=1)

# Fit the model
resnet_history = resnet_model.fit(train_datagen,
                                  epochs=5,
                                  steps_per_epoch=len(train_datagen),
                                  validation_data=test_datagen,
                                  validation_steps=len(test_datagen),
                                  # Add TensorBoard callback to model (callbacks parameter takes a list)
                                  callbacks = [checkpoint_callback]
)

"""# Save the model"""

resnet_model.save("resnet_model.h5")

"""# Load the model"""

# resnet_model = tf.keras.models.load_model('resnet_model.h5')
resnet_model = tf.keras.models.load_model(('resnet_model.h5'),custom_objects={'KerasLayer':hub.KerasLayer})

"""# Evaluate the model"""

plot_loss_curves(resnet_history)

resnet_model.evaluate(test_datagen)

# Plot the training curves
import pandas as pd
pd.DataFrame(resnet_history.history).plot(figsize=(10, 7));

# Create a function to import an image and resize it to be able to be used with our model
def load_and_prep_image(filename, img_shape=IMAGE_SHAPE):
  """
  Reads an image from filename, crops the image, turns it into a tensor
  and reshapes it to (img_shape, img_shape, colour_channel).
  """
  # Read in target file (an image)
  # img = crop_img(filename)
  img = crop_img(filename)
  img = tf.io.read_file(filename)

  # Decode the read file into a tensor & ensure 3 colour channels 
  # (our model is trained on images with 3 colour channels and sometimes images have 4 colour channels)
  img = tf.image.decode_image(img, channels=3)

  # Resize the image (to the same size our model was trained on)
  # img = tf.image.resize(img, size = [img_shape, img_shape])
  im_shp = 224
  img = tf.image.resize(img, size = [im_shp, im_shp])

  # Rescale the image (get all values between 0 and 1)
  img = img/255.
  return img

img = load_and_prep_image("real_1.jpg") # load in target image and turn it into tensor
resnet_model.predict(tf.expand_dims(img, axis=0))

img = load_and_prep_image("fake_1.jpg") # load in target image and turn it into tensor
resnet_model.predict(tf.expand_dims(img, axis=0))

import numpy as np
import matplotlib.pyplot as plt
def make_pred(img):
  """
  Takes a filename and makes a prediction
  """
  img = load_and_prep_image(img)
  prob = (resnet_model.predict(tf.expand_dims(img, axis=0)))
  print(prob)
  result = int(np.round(prob))
  classes = ["fake", "real"]
  plt.imshow(img)
  print("Predicted class: ", classes[result])

make_pred("real_1.jpg")

make_pred("fake_1.jpg")

make_pred("real_2.jpg")

make_pred("fake_2.jpg")

"""# Cropping the face from the entire photo"""

import cv2
from google.colab.patches import cv2_imshow

def crop_img(img_name):
  """
  Takes a file name (img_name) and returns the cropped photo including only the face.
  """
  # Read the input image
  img = cv2.imread(img_name)

  # Convert into grayscale
  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

  # Load the cascade
  face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

  # Detect faces
  faces = face_cascade.detectMultiScale(gray, 1.1, 4)

  # # Draw rectangle around the faces and crop the faces
  for (x, y, w, h) in faces:
    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 255), 2)
    faces = img[y:y + h, x:x + w]
    # cv2_imshow(faces)
    cv2.imwrite(img_name, faces)
  return img
 
	
# # Display the output
# cv2.imwrite('detcted.jpg', img)
# cv2_imshow(img)
# cv2.waitKey()

make_pred("full_photo.jpg")

make_pred("full_id.jpg")

